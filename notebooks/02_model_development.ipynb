{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a658af9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks/02_model_development.ipynb\n",
    "# Run in: VS Code or Colab\n",
    "\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Stock Price Prediction Model Development\\n\",\n",
    "    \"Development and comparison of different machine learning models\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"project_root = Path.cwd().parent\\n\",\n",
    "    \"sys.path.insert(0, str(project_root))\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.data.data_loader import DataLoader\\n\",\n",
    "    \"from src.models.linear_regression import LinearRegressionModel\\n\",\n",
    "    \"from src.models.random_forest import RandomForestModel\\n\",\n",
    "    \"from src.models.xgboost_model import XGBoostModel\\n\",\n",
    "    \"from src.models.ensemble import EnsembleModel\\n\",\n",
    "    \"from src.models.model_evaluator import ModelEvaluator\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Prepare Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"data_loader = DataLoader()\\n\",\n",
    "    \"symbol = 'AAPL'\\n\",\n",
    "    \"period = '2y'\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loading {symbol} data...\\\")\\n\",\n",
    "    \"df = data_loader.load_stock_data(symbol, period=period)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Data shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Date range: {df.index.min()} to {df.index.max()}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"plt.plot(df.index, df['Close'], linewidth=2)\\n\",\n",
    "    \"plt.title(f'{symbol} Historical Price', fontweight='bold', fontsize=14)\\n\",\n",
    "    \"plt.xlabel('Date')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Linear Regression Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n=== Training Linear Regression Model ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"lr_model = LinearRegressionModel()\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = lr_model.split_data(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training samples: {len(X_train)}\\\")\\n\",\n",
    "    \"print(f\\\"Testing samples: {len(X_test)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"lr_model.build()\\n\",\n",
    "    \"lr_model.train(X_train, y_train, X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"lr_metrics = lr_model.evaluate(X_test, y_test)\\n\",\n",
    "    \"print(f\\\"\\\\nLinear Regression Metrics:\\\")\\n\",\n",
    "    \"for key, value in lr_metrics.items():\\n\",\n",
    "    \"    print(f\\\"  {key}: {value:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred_lr = lr_model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"plt.plot(y_test.values, label='Actual', linewidth=2)\\n\",\n",
    "    \"plt.plot(y_pred_lr, label='Predicted', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"plt.title('Linear Regression: Actual vs Predicted', fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Sample')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Random Forest Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n=== Training Random Forest Model ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"rf_model = RandomForestModel(n_estimators=100)\\n\",\n",
    "    \"rf_model.build()\\n\",\n",
    "    \"rf_model.train(X_train, y_train, X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"rf_metrics = rf_model.evaluate(X_test, y_test)\\n\",\n",
    "    \"print(f\\\"\\\\nRandom Forest Metrics:\\\")\\n\",\n",
    "    \"for key, value in rf_metrics.items():\\n\",\n",
    "    \"    print(f\\\"  {key}: {value:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred_rf = rf_model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"plt.plot(y_test.values, label='Actual', linewidth=2)\\n\",\n",
    "    \"plt.plot(y_pred_rf, label='Predicted', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"plt.title('Random Forest: Actual vs Predicted', fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Sample')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"feature_importance = rf_model.get_feature_importance()\\n\",\n",
    "    \"print(f\\\"\\\\nTop 10 Features:\\\")\\n\",\n",
    "    \"print(feature_importance.head(10))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. XGBoost Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n=== Training XGBoost Model ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"xgb_model = XGBoostModel(n_estimators=100)\\n\",\n",
    "    \"xgb_model.build()\\n\",\n",
    "    \"xgb_model.train(X_train, y_train, X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"xgb_metrics = xgb_model.evaluate(X_test, y_test)\\n\",\n",
    "    \"print(f\\\"\\\\nXGBoost Metrics:\\\")\\n\",\n",
    "    \"for key, value in xgb_metrics.items():\\n\",\n",
    "    \"    print(f\\\"  {key}: {value:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred_xgb = xgb_model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"plt.plot(y_test.values, label='Actual', linewidth=2)\\n\",\n",
    "    \"plt.plot(y_pred_xgb, label='Predicted', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"plt.title('XGBoost: Actual vs Predicted', fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Sample')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Ensemble Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n=== Training Ensemble Model ===\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"models_dict = {\\n\",\n",
    "    \"    'linear_regression': lr_model,\\n\",\n",
    "    \"    'random_forest': rf_model,\\n\",\n",
    "    \"    'xgboost': xgb_model\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"ensemble_model = EnsembleModel(models=models_dict)\\n\",\n",
    "    \"ensemble_model.feature_names = lr_model.feature_names\\n\",\n",
    "    \"ensemble_model.is_trained = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"ensemble_model.optimize_weights(X_test, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nOptimized Weights:\\\")\\n\",\n",
    "    \"print(ensemble_model.get_model_contributions())\\n\",\n",
    "    \"\\n\",\n",
    "    \"y_pred_ensemble = ensemble_model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ensemble_metrics = ensemble_model.evaluate(X_test, y_test)\\n\",\n",
    "    \"print(f\\\"\\\\nEnsemble Metrics:\\\")\\n\",\n",
    "    \"for key, value in ensemble_metrics.items():\\n\",\n",
    "    \"    print(f\\\"  {key}: {value:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"plt.plot(y_test.values, label='Actual', linewidth=2)\\n\",\n",
    "    \"plt.plot(y_pred_ensemble, label='Ensemble', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"plt.title('Ensemble: Actual vs Predicted', fontweight='bold')\\n\",\n",
    "    \"plt.xlabel('Sample')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Model Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"comparison_df = pd.DataFrame([\\n\",\n",
    "    \"    {'Model': 'Linear Regression', **lr_metrics},\\n\",\n",
    "    \"    {'Model': 'Random Forest', **rf_metrics},\\n\",\n",
    "    \"    {'Model': 'XGBoost', **xgb_metrics},\\n\",\n",
    "    \"    {'Model': 'Ensemble', **ensemble_metrics}\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nModel Comparison:\\\")\\n\",\n",
    "    \"print(comparison_df[['Model', 'r2_score', 'rmse', 'mae', 'mape']])\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"comparison_df.plot(x='Model', y='r2_score', kind='bar', ax=axes[0, 0], legend=False)\\n\",\n",
    "    \"axes[0, 0].set_title('R² Score', fontweight='bold')\\n\",\n",
    "    \"axes[0, 0].set_ylabel('Score')\\n\",\n",
    "    \"axes[0, 0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"comparison_df.plot(x='Model', y='rmse', kind='bar', axes[0, 1].set_title('RMSE', fontweight='bold')\\n\",\n",
    "    \"axes[0, 1].set_ylabel('Error')\\n\",\n",
    "    \"axes[0, 1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"comparison_df.plot(x='Model', y='mae', kind='bar', ax=axes[1, 0], legend=False, color='orange')\\n\",\n",
    "    \"axes[1, 0].set_title('MAE', fontweight='bold')\\n\",\n",
    "    \"axes[1, 0].set_ylabel('Error')\\n\",\n",
    "    \"axes[1, 0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"comparison_df.plot(x='Model', y='mape', kind='bar', ax=axes[1, 1], legend=False, color='green')\\n\",\n",
    "    \"axes[1, 1].set_title('MAPE (%)', fontweight='bold')\\n\",\n",
    "    \"axes[1, 1].set_ylabel('Error (%)')\\n\",\n",
    "    \"axes[1, 1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Prediction Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"plt.figure(figsize=(16, 8))\\n\",\n",
    "    \"plt.plot(y_test.values, label='Actual', linewidth=3, color='black')\\n\",\n",
    "    \"plt.plot(y_pred_lr, label='Linear Regression', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"plt.plot(y_pred_rf, label='Random Forest', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"plt.plot(y_pred_xgb, label='XGBoost', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"plt.plot(y_pred_ensemble, label='Ensemble', linewidth=2, alpha=0.7)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.title('All Models: Actual vs Predicted Prices', fontweight='bold', fontsize=14)\\n\",\n",
    "    \"plt.xlabel('Sample')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Future Price Prediction\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"forecast_days = 30\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nGenerating {forecast_days}-day forecast...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"forecast_lr = lr_model.predict_future(df, days=forecast_days)\\n\",\n",
    "    \"forecast_rf = rf_model.predict_future(df, days=forecast_days)\\n\",\n",
    "    \"forecast_xgb = xgb_model.predict_future(df, days=forecast_days)\\n\",\n",
    "    \"forecast_ensemble = ensemble_model.predict_future(df, days=forecast_days)\\n\",\n",
    "    \"\\n\",\n",
    "    \"forecast_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=forecast_days)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(16, 8))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.plot(df.index[-60:], df['Close'].values[-60:], label='Historical', linewidth=3, color='black')\\n\",\n",
    "    \"plt.plot(forecast_dates, forecast_lr, label='LR Forecast', linewidth=2, linestyle='--', alpha=0.7)\\n\",\n",
    "    \"plt.plot(forecast_dates, forecast_rf, label='RF Forecast', linewidth=2, linestyle='--', alpha=0.7)\\n\",\n",
    "    \"plt.plot(forecast_dates, forecast_xgb, label='XGB Forecast', linewidth=2, linestyle='--', alpha=0.7)\\n\",\n",
    "    \"plt.plot(forecast_dates, forecast_ensemble, label='Ensemble Forecast', linewidth=3, linestyle='--', alpha=0.9)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.axvline(x=df.index[-1], color='red', linestyle=':', linewidth=2, label='Forecast Start')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.title(f'{symbol} Price Forecast ({forecast_days} Days)', fontweight='bold', fontsize=14)\\n\",\n",
    "    \"plt.xlabel('Date')\\n\",\n",
    "    \"plt.ylabel('Price ($)')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nForecast Summary:\\\")\\n\",\n",
    "    \"print(f\\\"Current Price: ${df['Close'].iloc[-1]:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Ensemble 30D Forecast: ${forecast_ensemble[-1]:.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Expected Change: {((forecast_ensemble[-1] - df['Close'].iloc[-1]) / df['Close'].iloc[-1] * 100):.2f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Residual Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"residuals_ensemble = y_test.values - y_pred_ensemble\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0, 0].scatter(y_pred_ensemble, residuals_ensemble, alpha=0.5)\\n\",\n",
    "    \"axes[0, 0].axhline(y=0, color='r', linestyle='--')\\n\",\n",
    "    \"axes[0, 0].set_title('Residuals vs Predicted', fontweight='bold')\\n\",\n",
    "    \"axes[0, 0].set_xlabel('Predicted Values')\\n\",\n",
    "    \"axes[0, 0].set_ylabel('Residuals')\\n\",\n",
    "    \"axes[0, 0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0, 1].hist(residuals_ensemble, bins=30, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"axes[0, 1].set_title('Residuals Distribution', fontweight='bold')\\n\",\n",
    "    \"axes[0, 1].set_xlabel('Residuals')\\n\",\n",
    "    \"axes[0, 1].set_ylabel('Frequency')\\n\",\n",
    "    \"axes[0, 1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1, 0].plot(residuals_ensemble)\\n\",\n",
    "    \"axes[1, 0].axhline(y=0, color='r', linestyle='--')\\n\",\n",
    "    \"axes[1, 0].set_title('Residuals Over Time', fontweight='bold')\\n\",\n",
    "    \"axes[1, 0].set_xlabel('Sample')\\n\",\n",
    "    \"axes[1, 0].set_ylabel('Residuals')\\n\",\n",
    "    \"axes[1, 0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"stats.probplot(residuals_ensemble, dist=\\\"norm\\\", plot=axes[1, 1])\\n\",\n",
    "    \"axes[1, 1].set_title('Q-Q Plot', fontweight='bold')\\n\",\n",
    "    \"axes[1, 1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nResidual Statistics:\\\")\\n\",\n",
    "    \"print(f\\\"Mean: {np.mean(residuals_ensemble):.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Std Dev: {np.std(residuals_ensemble):.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Min: {np.min(residuals_ensemble):.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Max: {np.max(residuals_ensemble):.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Conclusion\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"MODEL DEVELOPMENT SUMMARY\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"best_model = comparison_df.loc[comparison_df['r2_score'].idxmax()]\\n\",\n",
    "    \"print(f\\\"\\\\nBest Model: {best_model['Model']}\\\")\\n\",\n",
    "    \"print(f\\\"R² Score: {best_model['r2_score']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"RMSE: {best_model['rmse']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"MAE: {best_model['mae']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"MAPE: {best_model['mape']:.2f}%\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nKey Findings:\\\")\\n\",\n",
    "    \"print(f\\\"1. Ensemble model achieves best overall performance\\\")\\n\",\n",
    "    \"print(f\\\"2. Random Forest provides good feature importance insights\\\")\\n\",\n",
    "    \"print(f\\\"3. XGBoost offers fast training with competitive accuracy\\\")\\n\",\n",
    "    \"print(f\\\"4. Linear Regression serves as a solid baseline\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
